[capture]
; Device used to capture
DevName =

; Pcap filename to run
PcapFile =

; dnstrap socket path. Example: unix:///tmp/dnstap.sock, tcp://127.0.0.1:8080
DnstapSocket =

; Port selected to filter packets
Port = 53

; Capture Sampling by a:b. eg sampleRatio of 1:100 will process 1 percent of the incoming packets
SampleRatio = 1:1

; Cleans up packet hash table used for deduplication
DedupCleanupInterval = 1m0s

; Set the dnstap socket permission, only applicable when unix:// is used
DnstapPermission = 755

; Number of routines used to handle received packets
PacketHandlerCount = 2

; Size of the tcp assembler
TcpAssemblyChannelSize = 10000

; Size of the tcp result channel
TcpResultChannelSize = 10000

; Number of routines used to handle tcp assembly
TcpHandlerCount = 1

; Size of the channel to send packets to be defragged
DefraggerChannelSize = 10000

; Size of the channel where the defragged packets are returned
DefraggerChannelReturnSize = 10000

; Size of the packet handler channel
PacketChannelSize = 1000

; Afpacket Buffersize in MB
AfpacketBuffersizeMb = 64

; BPF filter applied to the packet stream. If port is selected, the packets will not be defragged.
Filter = ((ip and (ip[9] == 6 or ip[9] == 17)) or (ip6 and (ip6[6] == 17 or ip6[6] == 6 or ip6[6] == 44)))

; Use AFPacket for live captures. Supported on Linux 3.0+ only
UseAfpacket = false

; The PCAP capture does not contain ethernet frames
NoEthernetframe = false

; Deduplicate incoming packets, Only supported with --devName and --pcapFile. Experimental 
Dedup = false

[clickhouse_output]
; Address of the clickhouse database to save the results
ClickhouseAddress = localhost:9000

; Username to connect to the clickhouse database
ClickhouseUsername =

; Password to connect to the clickhouse database
ClickhousePassword =

; Database to connect to the clickhouse database
ClickhouseDatabase = default

; Interval between sending results to ClickHouse
ClickhouseDelay = 1s

; Debug Clickhouse connection
ClickhouseDebug = false

; Compress Clickhouse connection
ClickhouseCompress = false

; Use TLS for Clickhouse connection
ClickhouseSecure = false

; Save full packet query and response in JSON format.
ClickhouseSaveFullQuery = false

; What should be written to clickhouse. options:
;	0: Disable Output
;	1: Enable Output without any filters
;	2: Enable Output and apply skipdomains logic
;	3: Enable Output and apply allowdomains logic
;	4: Enable Output and apply both skip and allow domains logic
ClickhouseOutputType = 0

; Minimun capacity of the cache array used to send data to clickhouse. Set close to the queries per second received to prevent allocations
ClickhouseBatchSize = 100000

; Number of Clickhouse output Workers
ClickhouseWorkers = 1

; Channel Size for each Clickhouse Worker
ClickhouseWorkerChannelSize = 100000

[elastic_output]
; What should be written to elastic. options:
;	0: Disable Output
;	1: Enable Output without any filters
;	2: Enable Output and apply skipdomains logic
;	3: Enable Output and apply allowdomains logic
;	4: Enable Output and apply both skip and allow domains logic
ElasticOutputType = 0

; elastic endpoint address, example: http://127.0.0.1:9200. Used if elasticOutputType is not none
ElasticOutputEndpoint =

; elastic index
ElasticOutputIndex = default

; Send data to Elastic in batch sizes
ElasticBatchSize = 1000

; Interval between sending results to Elastic if Batch size is not filled
ElasticBatchDelay = 1s

[file_output]
; What should be written to file. options:
;	0: Disable Output
;	1: Enable Output without any filters
;	2: Enable Output and apply skipdomains logic
;	3: Enable Output and apply allowdomains logic
;	4: Enable Output and apply both skip and allow domains logic
FileOutputType = 0

; Path to output file. Used if fileOutputType is not none
FileOutputPath =

; Output format for file. options:json,csv. note that the csv splits the datetime format into multiple fields
FileOutputFormat = json

[influx_output]
; What should be written to influx. options:
;	0: Disable Output
;	1: Enable Output without any filters
;	2: Enable Output and apply skipdomains logic
;	3: Enable Output and apply allowdomains logic
;	4: Enable Output and apply both skip and allow domains logic
InfluxOutputType = 0

; influx Server address, example: http://localhost:8086. Used if influxOutputType is not none
InfluxOutputServer =

; Influx Server Auth Token
InfluxOutputToken = dnsmonster

; Influx Server Bucket
InfluxOutputBucket = dnsmonster

; Influx Server Org
InfluxOutputOrg = dnsmonster

; Minimun capacity of the cache array used to send data to Influx
InfluxOutputWorkers = 8

; Minimun capacity of the cache array used to send data to Influx
InfluxBatchSize = 1000

[kafka_output]
; What should be written to kafka. options:
;	0: Disable Output
;	1: Enable Output without any filters
;	2: Enable Output and apply skipdomains logic
;	3: Enable Output and apply allowdomains logic
;	4: Enable Output and apply both skip and allow domains logic
KafkaOutputType = 0

; kafka broker address(es), example: 127.0.0.1:9092. Used if kafkaOutputType is not none
KafkaOutputBroker =

; Kafka topic for logging
KafkaOutputTopic = dnsmonster

; Minimun capacity of the cache array used to send data to Kafka
KafkaBatchSize = 1000

; Interval between sending results to Kafka if Batch size is not filled
KafkaBatchDelay = 1s

; Compress Kafka connection
KafkaCompress = false

[sentinel_output]
; What should be written to Microsoft Sentinel. options:
;	0: Disable Output
;	1: Enable Output without any filters
;	2: Enable Output and apply skipdomains logic
;	3: Enable Output and apply allowdomains logic
;	4: Enable Output and apply both skip and allow domains logic
SentinelOutputType = 0

; Sentinel Shared Key, either the primary or secondary, can be found in Agents Management page under Log Analytics workspace
SentinelOutputSharedKey =

; Sentinel Customer Id. can be found in Agents Management page under Log Analytics workspace
SentinelOutputCustomerId =

; Sentinel Output LogType
SentinelOutputLogType = dnsmonster

; Sentinel Output Proxy in URI format
SentinelOutputProxy =

; Sentinel Batch Size
SentinelBatchSize = 100

; Interval between sending results to Sentinel if Batch size is not filled
SentinelBatchDelay = 1s

[splunk_output]
; What should be written to HEC. options:
;	0: Disable Output
;	1: Enable Output without any filters
;	2: Enable Output and apply skipdomains logic
;	3: Enable Output and apply allowdomains logic
;	4: Enable Output and apply both skip and allow domains logic
SplunkOutputType = 0

; splunk endpoint address, example: http://127.0.0.1:8088. Used if splunkOutputType is not none, can be specified multiple times for load balanace and HA
SplunkOutputEndpoint =

; Splunk HEC Token
SplunkOutputToken = 00000000-0000-0000-0000-000000000000

; Splunk Output Index
SplunkOutputIndex = temp

; Splunk Output Source
SplunkOutputSource = dnsmonster

; Splunk Output Sourcetype
SplunkOutputSourceType = json

; Send data to HEC in batch sizes
SplunkBatchSize = 1000

; Interval between sending results to HEC if Batch size is not filled
SplunkBatchDelay = 1s

[stdout_output]
; What should be written to stdout. options:
;	0: Disable Output
;	1: Enable Output without any filters
;	2: Enable Output and apply skipdomains logic
;	3: Enable Output and apply allowdomains logic
;	4: Enable Output and apply both skip and allow domains logic
StdoutOutputType = 0

; Output format for stdout. options:json,csv. note that the csv splits the datetime format into multiple fields
StdoutOutputFormat = json

; Number of workers
StdoutOutputWorkerCount = 8

[syslog_output]
; What should be written to Syslog server. options:
;	0: Disable Output
;	1: Enable Output without any filters
;	2: Enable Output and apply skipdomains logic
;	3: Enable Output and apply allowdomains logic
;	4: Enable Output and apply both skip and allow domains logic
SyslogOutputType = 0

; Syslog endpoint address, example: udp://127.0.0.1:514, tcp://127.0.0.1:514. Used if syslogOutputType is not none
SyslogOutputEndpoint = udp://127.0.0.1:514

[general]
; Garbage Collection interval for tcp assembly and ip defragmentation
GcTime = 10s

; Duration to calculate interface stats
CaptureStatsDelay = 1s

; Duration to print capture and database stats
PrintStatsDelay = 10s

; Mask IPv4s by bits. 32 means all the bits of IP is saved in DB
MaskSize4 = 32

; Mask IPv6s by bits. 32 means all the bits of IP is saved in DB
MaskSize6 = 128

; Name of the server used to index the metrics.
ServerName = default

; Set debug Log level, 0:PANIC, 1:ERROR, 2:WARN, 3:INFO, 4:DEBUG
LogLevel = 3

; Size of the result processor channel size
ResultChannelSize = 100000

; write cpu profile to file
Cpuprofile =

; write memory profile to file
Memprofile =

; GOMAXPROCS variable
Gomaxprocs = -1

; Limit of packets logged to clickhouse every iteration. Default 0 (disabled)
PacketLimit = 0

; Skip outputing domains matching items in the CSV file path. Can accept a URL (http:// or https://) or path
SkipDomainsFile =

; Hot-Reload skipDomainsFile interval
SkipDomainsRefreshInterval = 1m0s

; skipDomainsFile type. Options: csv and hashtable. Hashtable is ONLY fqdn, csv can support fqdn, prefix and suffix logic but it's much slower
SkipDomainsFileType = csv

; Allow Domains logic input file. Can accept a URL (http:// or https://) or path
AllowDomainsFile =

; Hot-Reload allowDomainsFile file interval
AllowDomainsRefreshInterval = 1m0s

; allowDomainsFile type. Options: csv and hashtable. Hashtable is ONLY fqdn, csv can support fqdn, prefix and suffix logic but it's much slower
AllowDomainsFileType = csv

; Skip TLS verification when making HTTPS connections
SkipTLSVerification = false

